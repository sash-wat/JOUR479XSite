p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows for seasons
#p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric)
return(p3)
}
temp <- getFBRefData("https://fbref.com/en/players/d70ce98e/Lionel-Messi")
temp
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url) {
# Read the HTML content from the webpage
webpage <- read_html(url)
# Specify the ID of the table you want to extract
table_id <- "stats_standard_dom_lg"  # Replace with your table ID
# Extract the table using its ID
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
#p3 <- html_table(p3, header=TRUE, fill=TRUE)[[4]]
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows for seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric)
return(p3)
}
temp <- getFBRefData("https://fbref.com/en/players/d70ce98e/Lionel-Messi")
temp
temp <- getFBRefData("https://fbref.com/en/players/c3ee18ef/Lucas-Hernandez")
temp
temp <- getFBRefData("https://fbref.com/en/players/1f44ac21/Erling-Haaland")
temp
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url) {
webpage <- read_html(url)
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
temp <- getFBRefData("https://fbref.com/en/players/1f44ac21/Erling-Haaland")
temp
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url) {
webpage <- read_html(url)
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
temp <- getFBRefData("https://fbref.com/en/players/c3ee18ef/Lucas-Hernandez")
temp
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url) {
webpage <- read_html(url)
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url) {
webpage <- read_html(url)
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
temp <- getFBRefData("https://fbref.com/en/players/1f44ac21/Erling-Haaland")
temp
temp <- getFBRefData("https://fbref.com/en/players/7a2e46a8/Alisson")
temp
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url, gk="no") {
webpage <- read_html(url)
if (gk == "no") {
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (gk =="yes") {
table_id <- "stats_keeper_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
}
temp <- getFBRefData("https://fbref.com/en/players/7a2e46a8/Alisson")
temp
rm(list=ls())
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url, gk="no") {
webpage <- read_html(url)
if (gk == "no") {
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (gk =="yes") {
table_id <- "stats_keeper_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
}
temp <- getFBRefData("https://fbref.com/en/players/7a2e46a8/Alisson", "yes")
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url, gk="no") {
webpage <- read_html(url)
if (gk == "no") {
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (gk =="yes") {
table_id <- "stats_keeper_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
#p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
}
temp <- getFBRefData("https://fbref.com/en/players/7a2e46a8/Alisson", "yes")
rm(list-ls())
rm(list=ls())
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url, gk="no") {
webpage <- read_html(url)
if (gk == "no") {
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (gk =="yes") {
table_id <- "stats_keeper_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
#p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
}
temp <- getFBRefData("https://fbref.com/en/players/7a2e46a8/Alisson", "yes")
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url, gk="no") {
webpage <- read_html(url)
if (gk == "no") {
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (gk =="yes") {
table_id <- "stats_keeper_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
names(p3)[15] <- "NormalSave%"
names(p3)[25] <- "PenSave%"
#p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
}
temp <- getFBRefData("https://fbref.com/en/players/7a2e46a8/Alisson", "yes")
temp
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url, gk="no") {
webpage <- read_html(url)
if (gk == "no") {
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (gk =="yes") {
table_id <- "stats_keeper_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
names(p3)[15] <- "NormalSave%"
names(p3)[25] <- "PenSave%"
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
}
temp <- getFBRefData("https://fbref.com/en/players/7a2e46a8/Alisson", "yes")
temp
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url, pos="A/M") {
webpage <- read_html(url)
if (pos == "A/M") {
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (pos =="GK") {
table_id <- "stats_keeper_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
names(p3)[15] <- "NormalSave%"
names(p3)[25] <- "PenSave%"
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (pos =="DEF") {
table_id <- "stats_defense_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
names(p3)[13] <- "TklChall"
p3 <- p3 |> select(1:23)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:23, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
}
temp <- getFBRefData("https://fbref.com/en/players/132a82f1/Wesley-Fofana", "DEF")
library(rvest)
library(janitor)
library(ggplot2)
getFBRefData <- function(url, pos="A/M") {
webpage <- read_html(url)
if (pos == "A/M") {
table_id <- "stats_standard_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (pos =="GK") {
table_id <- "stats_keeper_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
names(p3)[15] <- "NormalSave%"
names(p3)[25] <- "PenSave%"
p3 <- p3 |> select(1:25)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:25, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
if (pos =="DEF") {
table_id <- "stats_defense_dom_lg"
p3 <- webpage %>% html_node(paste("#", table_id, sep = "")) %>% html_table()
p3 <- row_to_names(p3, 1, remove_rows_above = FALSE)
names(p3)[13] <- "TklChall"
p3 <- p3 |> select(1:23)
regex <- "[0-9]{4}-[0-9]{4}|[0-9]{4}"
p3 <- p3 |> filter(cumsum(!grepl(regex, Season)) == 0) #This line drops all rows after the individual seasons
#p3$Min <- as.numeric(gsub(",", "", p3$Min))
p3 <- p3 |> mutate_at(7:23, as.numeric) #turn all the actual data columns into numbers
return(p3)
}
}
temp <- getFBRefData("https://fbref.com/en/players/132a82f1/Wesley-Fofana", "DEF")
temp
library(tidyverse)
library(ggbeeswarm)
library(ggrepel)
library(ggalt)
set.seed(1234)
playerswbb <- read_csv("https://thescoop.org/sports-data-files/wbb_players_2023.csv")
activeplayers <- playerswbb |> filter(position %in% c("C", "F", "G")) |> filter(mp>0)
activeplayers <- activeplayers |> mutate(tspct=pts/(2*(fga+0.44*fta)))
summary(activeplayers$fga)
shooters <- activeplayers |> filter(fga > 187)
ggplot() + geom_beeswarm(data=shooters, aes(x=position, y=tspct), color="grey")
umd <- activeplayers |>
filter(team == "Maryland") |>
filter(fga>187) |>
arrange(desc(tspct))
ggplot() +
geom_beeswarm(
data=shooters,
groupOnX=TRUE,
aes(x=position, y=tspct), color="grey") +
geom_beeswarm(
data=umd,
groupOnX=TRUE,
aes(x=position, y=tspct), color="red")
ggplot() +
geom_beeswarm(
data=shooters,
groupOnX=TRUE,
aes(x=position, y=tspct), color="grey") +
geom_beeswarm(
data=umd,
groupOnX=TRUE,
aes(x=position, y=tspct), color="red") +
geom_text_repel(
data=umd,
aes(x=position, y=tspct, label=player))
ggplot() +
geom_quasirandom(
data=shooters,
groupOnX=TRUE,
aes(x=position, y=tspct), color="grey") +
geom_quasirandom(
data=umd,
groupOnX=TRUE,
aes(x=position, y=tspct), color="red") +
geom_text_repel(
data=umd,
aes(x=position, y=tspct, label=player))
ggplot() +
geom_jitter(
data=shooters,
aes(x=position, y=tspct), color="grey") +
geom_jitter(
data=umd,
aes(x=position, y=tspct), color="red") +
geom_text_repel(
data=umd,
aes(x=position, y=tspct, label=player))
players <- read_csv("https://raw.githubusercontent.com/dwillis/hhs-snapshots/main/data/player_totals_20231130.csv") |> filter(mp > 0)
ggplot() + geom_point(data=players, aes(x=mp, y=pts))
topscorers <- players |> filter(pts > 175)
ggplot() +
geom_point(data=players, aes(x=mp, y=pts), color="grey") +
geom_point(data=topscorers, aes(x=mp, y=pts), color="black")
ggplot() +
geom_point(data=players, aes(x=mp, y=pts), color="grey") +
geom_point(data=topscorers, aes(x=mp, y=pts), color="black") +
geom_encircle(data=topscorers, aes(x=mp, y=pts), s_shape=1, expand=1, colour="red")
ggplot() +
geom_point(data=players, aes(x=mp, y=pts), color="grey") +
geom_point(data=topscorers, aes(x=mp, y=pts), color="black") +
geom_encircle(data=topscorers, aes(x=mp, y=pts), s_shape=0, expand=0, colour="red")
ggplot() +
geom_point(data=players, aes(x=mp, y=pts), color="grey") +
geom_point(data=topscorers, aes(x=mp, y=pts), color="black") +
geom_text(data=topscorers, aes(x=mp, y=pts, label=full_name), hjust = 0, vjust=1) +
geom_encircle(data=topscorers, aes(x=mp, y=pts), s_shape=.5, expand=.03, colour="red")
ggplot() +
geom_point(data=players, aes(x=mp, y=pts), color="grey") +
geom_point(data=topscorers, aes(x=mp, y=pts), color="black") +
geom_encircle(data=topscorers, aes(x=mp, y=pts), s_shape=.5, expand=.03, colour="red") +
geom_text(aes(x=275, y=275, label="Top scorers")) +
labs(title="Caitlin Clark Alone At Top", subtitle="The Iowa star is by far the top scorer among all NCAA players", x="Minutes", y="Points") +
theme_minimal() +
theme(
plot.title = element_text(size = 16, face = "bold"),
axis.title = element_text(size = 8),
plot.subtitle = element_text(size=10),
panel.grid.minor = element_blank()
)
logs <- read_csv("https://thescoop.org/sports-data-files/wbblogs24.csv")
rankings <- read_csv("https://thescoop.org/sports-data-files/wbb_rankings.csv")
logs23 <- read_csv("https://thescoop.org/sports-data-files/wbblogs23.csv")
View(rankings)
View(logs)
logs <- read_csv("https://thescoop.org/sports-data-files/wbblogs24.csv")
rankings <- read_csv("https://thescoop.org/sports-data-files/wbb_rankings.csv")
logs23 <- read_csv("https://thescoop.org/sports-data-files/wbblogs23.csv")
parity_index24 <- logs |>
group_by(Team, Conference) |>
summarise(srs_score = mean(TeamSRS), sos_score = mean(TeamSOS)) |>
mutate(parity_index = (srs_score + 100) / (sos_score + 100))
parity_index23 <- logs23 |>
group_by(Team, Conference) |>
summarise(srs_score = mean(TeamSRS), sos_score = mean(TeamSOS)) |>
mutate(parity_index = (srs_score + 100) / (sos_score + 100))
View(parity_index23)
View(parity_index24)
parity_index24 |>
filter(Conference == 'Big Ten WBB') |>
ggplot() +
geom_point(aes(x=srs_score, y = sos_score, label = Team)) +
geom_text(aes(x=srs_score, y = sos_score, label = Team))
parity_index24 |>
filter(Conference == 'SEC WBB') |>
ggplot() +
geom_point(aes(x=srs_score, y = sos_score, label = Team)) +
geom_text(aes(x=srs_score, y = sos_score, label = Team))
parity_index24 |>
filter(Conference == 'Big 12 WBB') |>
ggplot() +
geom_point(aes(x=srs_score, y = sos_score, label = Team)) +
geom_text(aes(x=srs_score, y = sos_score, label = Team))
parity_with_top25 <- parity_index24 |> left_join(rankings, join_by(Team == team))
View(parity_with_top25)
parity_with_top25 <- parity_index24 |> left_join(rankings, join_by(Team == team))
combined_data <- bind_rows(parity_index24 |> mutate(season="2024"), parity_index23 |> mutate(season = "2023"))
result <- combined_data %>%
group_by(Team) %>%
summarize(
Parity_Index_2024 = mean(parity_index[season == "2024"]),
Parity_Index_2023 = mean(parity_index[season == "2023"])
) %>%
filter(!is.na(Parity_Index_2024)) |>
filter(!is.na(Parity_Index_2023)) |>
ungroup() %>%
summarise(
p_value = t.test(Parity_Index_2024, Parity_Index_2023, paired = TRUE)$p.value,
mean_difference = mean(Parity_Index_2024 - Parity_Index_2023)
)
View(result)
